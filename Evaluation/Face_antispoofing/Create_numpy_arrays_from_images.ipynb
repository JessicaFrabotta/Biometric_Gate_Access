{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d20e669-8099-4fc7-b4e1-07d4ba2fda24",
   "metadata": {},
   "source": [
    "## Create cropped datsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df1abb-70a3-459e-a08a-7b1ba12a7d75",
   "metadata": {},
   "source": [
    "This code is designed to process and extract data from two biometric datasets NUAA Photograph Imposter Database and MSU-MFSD used for tasks like face anti spoofing (distinguishing between real and fake faces). The code involves three main stages:\n",
    "\n",
    "**1. Preprocessing images from videos using MTCNN:**\n",
    "it uses the MTCNN (Multi-task Cascaded Convolutional Networks) model to detect faces in video frames, extract them, and save the cropped faces to new directories. This process is repeated for both the NUAA and MSU datasets, storing cropped faces from \"real\" and \"attack\" categories.\n",
    "\n",
    "**2. Loading images and generating numpy arrays:**\n",
    "for the NUAA dataset, the code reads image paths from text files, loads the images from disk, resizes them and stores them in numpy arrays alongside their corresponding labels. A similar process is applied to the MSU-MFSD dataset, where images are loaded from directories, their corresponding identity is extracted from filenames and the real/fake labels are assigned based on the folder structure.\n",
    "\n",
    "**3. Dataset combination and shuffling:**\n",
    "after processing both datasets, they are combined into a larger dataset by concatenating the image data and labels from both datasets. For the MSU dataset, a subset of 19,000 images from each category (real and attack) is selected at random, and all the data is shuffled to ensure randomization in the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4553b3b-cf96-48ee-8e68-288c4e3b464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "from facenet_pytorch import MTCNN, training\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "903a7603-17eb-4cbf-82d4-222e34a22ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "data_dir_nuaa = r'C:\\Users\\Asus\\Desktop\\Biometric Systems\\Datasets\\NUAA Photograph Imposter Database\\raw'\n",
    "data_dir_msu = r'C:\\Users\\Asus\\Desktop\\Biometric Systems\\Datasets\\MSU-MFSD Photos\\raw'\n",
    "\n",
    "batch_size = 16\n",
    "workers = 0 if os.name == 'nt' else 8\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress all warnings\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c684f71f-8d23-4df7-8a7a-c818b5e39920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MTCNN model for face detection\n",
    "mtcnn = MTCNN(\n",
    "    image_size=224, # Resize detected face to 224x224 pixels\n",
    "    margin=14, # Add a 14-pixel margin around the detected face\n",
    "    device=device,\n",
    "    selection_method='center_weighted_size' # Choose the best face based on center and size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab1fee91-3712-4ac1-84a1-619793169416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data loader for the input set of images\n",
    "orig_img_ds = datasets.ImageFolder(data_dir, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "becdb451-deee-488c-aa0c-6270cef0fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_img_ds.samples = [\n",
    "    (p, p)\n",
    "    for p, _ in orig_img_ds.samples\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "367d1c4d-f404-4fae-a231-0e97b3489296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a data loader to load the images in batches\n",
    "loader = DataLoader(\n",
    "    orig_img_ds,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=training.collate_pil\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "30673da6-fbc7-4b80-87eb-226ae88ca15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 789 of 789\n"
     ]
    }
   ],
   "source": [
    "# Variables to store paths to cropped images and bounding box probabilities for the NUAA dataset\n",
    "crop_paths_nuaa = []\n",
    "box_probs_nuaa = []\n",
    "\n",
    "# Loop through the data loader in batches\n",
    "for i, (x, b_paths) in enumerate(loader):\n",
    "    # Prepare the save paths for the cropped faces (replace original directory with cropped one)\n",
    "    crops = [p.replace(data_dir, data_dir_nuaa + '_cropped') for p in b_paths]\n",
    "    # Detect faces in the images using MTCNN and save the cropped faces\n",
    "    mtcnn(x, save_path=crops)\n",
    "    crop_paths_nuaa.extend(crops)\n",
    "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dbb57fb9-483b-4a19-a624-d5cab1666feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4855 of 4855\n"
     ]
    }
   ],
   "source": [
    "# Repeat the same process for the MSU dataset\n",
    "crop_paths_msu = []\n",
    "box_probs_msu = []\n",
    "\n",
    "for i, (x, b_paths) in enumerate(loader):\n",
    "    crops = [p.replace(data_dir, data_dir_msu + '_cropped') for p in b_paths]\n",
    "    mtcnn(x, save_path=crops)\n",
    "    crop_paths_msu.extend(crops)\n",
    "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7d7816-2028-4f38-9333-d6cd4a323162",
   "metadata": {},
   "source": [
    "## Create numpy arrays from NUAA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9c0e228-d7b5-4422-a4b7-2214158358ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create numpy arrays from NUAA dataset\n",
    "\n",
    "# Folder paths for NUAA dataset (clients and imposters)\n",
    "raw_dir = r'C:\\Users\\Asus\\Desktop\\Biometric Systems\\Datasets\\NUAA Photograph Imposter Database\\raw_cropped'\n",
    "client_raw_dir = os.path.join(raw_dir, 'ClientRaw')\n",
    "imposter_raw_dir = os.path.join(raw_dir, 'ImposterRaw')\n",
    "\n",
    "# Text file paths that contain lists of image file names\n",
    "client_train_file = os.path.join(raw_dir, 'client_train_raw.txt')\n",
    "client_test_file = os.path.join(raw_dir, 'client_test_raw.txt')\n",
    "imposter_train_file = os.path.join(raw_dir, 'imposter_train_raw.txt')\n",
    "imposter_test_file = os.path.join(raw_dir, 'imposter_test_raw.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6e18497-22ec-42fe-b987-13a12124b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read image paths from a text file\n",
    "def read_image_paths(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        image_paths = file.read().splitlines()\n",
    "    return image_paths\n",
    "\n",
    "# Function to load images from paths\n",
    "def load_images(image_paths, base_dir, label, img_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    source_labels = []  # Used to differentiate between client (0) and imposter (1)\n",
    "\n",
    "    for path in tqdm(image_paths):\n",
    "        full_path = os.path.join(base_dir, path)\n",
    "        image = cv2.imread(full_path)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, img_size)\n",
    "            images.append(image)\n",
    "            id_str = os.path.normpath(path).split(os.sep)[0] # Extract client ID from the file path\n",
    "            labels.append(int(id_str))\n",
    "            source_labels.append(label) # Append the label (0 for client, 1 for imposter)\n",
    "\n",
    "    return images, labels, source_labels\n",
    "\n",
    "# Function to create the dataset for NUAA (returns image data, labels and source labels)\n",
    "def create_dataset(client_train_file, client_test_file, imposter_train_file, imposter_test_file, client_raw_dir, imposter_raw_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    S = []\n",
    "\n",
    "    # Load training and test images for clients (real faces)\n",
    "    client_train_paths = read_image_paths(client_train_file)\n",
    "    client_test_paths = read_image_paths(client_test_file)\n",
    "    imposter_train_paths = read_image_paths(imposter_train_file)\n",
    "    imposter_test_paths = read_image_paths(imposter_test_file)\n",
    "\n",
    "    # Load client (real) images for both training and test sets\n",
    "    client_images, client_labels, client_source_labels = load_images(client_train_paths, client_raw_dir, 0)\n",
    "    X.extend(client_images)\n",
    "    y.extend(client_labels)\n",
    "    S.extend(client_source_labels)\n",
    "\n",
    "    client_images, client_labels, client_source_labels = load_images(client_test_paths, client_raw_dir, 0)\n",
    "    X.extend(client_images)\n",
    "    y.extend(client_labels)\n",
    "    S.extend(client_source_labels)\n",
    "    \n",
    "    # Load imposter (fake) images for both training and test sets\n",
    "    imposter_images, imposter_labels, imposter_source_labels = load_images(imposter_train_paths, imposter_raw_dir, 1)\n",
    "    X.extend(imposter_images)\n",
    "    y.extend(imposter_labels)\n",
    "    S.extend(imposter_source_labels)\n",
    "\n",
    "    imposter_images, imposter_labels, imposter_source_labels = load_images(imposter_test_paths, imposter_raw_dir, 1)\n",
    "    X.extend(imposter_images)\n",
    "    y.extend(imposter_labels)\n",
    "    S.extend(imposter_source_labels)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    S = np.array(S)\n",
    "\n",
    "    return X, y, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dbb8a004-25d4-4294-a2e2-265e029fd0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1743/1743 [00:02<00:00, 849.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3362/3362 [00:03<00:00, 894.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1748/1748 [00:01<00:00, 962.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 5761/5761 [00:06<00:00, 833.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_nuaa shape: (12547, 224, 224, 3)\n",
      "y_nuaa shape: (12547,)\n",
      "S_nuaa shape: (12547,)\n"
     ]
    }
   ],
   "source": [
    "# Create numpy arrays for the NUAA dataset\n",
    "X_nuaa, y_nuaa, S_nuaa = create_dataset(client_train_file, client_test_file, imposter_train_file, imposter_test_file, client_raw_dir, imposter_raw_dir)\n",
    "\n",
    "print(f'X_nuaa shape: {X_nuaa.shape}')\n",
    "print(f'y_nuaa shape: {y_nuaa.shape}')\n",
    "print(f'S_nuaa shape: {S_nuaa.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "561730c0-aa5b-4472-a0af-ae2e99406da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy arrays saved successfully.\n"
     ]
    }
   ],
   "source": [
    "np.save('X_nuaa.npy', X_nuaa)\n",
    "np.save('y_nuaa.npy', y_nuaa)\n",
    "np.save('S_nuaa.npy', S_nuaa)\n",
    "\n",
    "print(\"Numpy arrays saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f04a6-1bf9-4901-9b40-c6bb1bcba24c",
   "metadata": {},
   "source": [
    "## Create numpy arrays from MSU-MFSD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ff13ce2a-f86c-4792-98c1-e60671be722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images and labels from the MSU dataset (real and attack images)\n",
    "def load_images_and_labels(base_dir, label):\n",
    "    images = []\n",
    "    identities = []\n",
    "    fake_real_types = [] # Used to differentiate real (0) and fake (1) faces\n",
    "\n",
    "    # Traverse the directory and read all .jpg images\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        for file in tqdm(files, desc=f\"Loading images from {label}\"):\n",
    "            if file.endswith('.jpg'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                img = cv2.imread(file_path)\n",
    "                img = cv2.resize(img, (224, 224)) # Resize to 224x224\n",
    "                images.append(img)\n",
    "                # Extract identity from the file name\n",
    "                match = re.search(r'client(\\d{3})_', file)\n",
    "                if match:\n",
    "                    identity = int(match.group(1))\n",
    "                else:\n",
    "                    identity = -1  # Default or error value if no match found\n",
    "                \n",
    "                identities.append(identity)\n",
    "                \n",
    "                # Assign real/fake label based on the directory structure\n",
    "                if 'real' in root:\n",
    "                    fake_real_types.append(0)\n",
    "                elif 'attack' in root:\n",
    "                    fake_real_types.append(1)\n",
    "    \n",
    "    return images, identities, fake_real_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "465c3e84-0d6e-44f7-9aa4-b85e61e9147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create numpy arrays for the MSU dataset (real and attack images)\n",
    "def create_numpy_arrays(real_dir, attack_dir):\n",
    "    # Load real images\n",
    "    real_images, real_identities, real_fake_real_types = load_images_and_labels(real_dir, 'real')\n",
    "    \n",
    "    # Load attack images\n",
    "    attack_images, attack_identities, attack_fake_real_types = load_images_and_labels(attack_dir, 'attack')\n",
    "    \n",
    "    # Combine real and attack images\n",
    "    all_images = real_images + attack_images\n",
    "    all_identities = real_identities + attack_identities\n",
    "    all_fake_real_types = real_fake_real_types + attack_fake_real_types\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(all_images)\n",
    "    identities = np.array(all_identities)\n",
    "    fake_real_types = np.array(all_fake_real_types)\n",
    "    \n",
    "    return X, identities, fake_real_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "62c84b12-f58e-4f27-b322-f9dd79373ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for the MSU dataset\n",
    "new_dataset_dir = r'C:\\Users\\Asus\\Desktop\\Biometric Systems\\Datasets\\MSU-MFSD Photos\\raw_cropped'\n",
    "real_dir = os.path.join(new_dataset_dir, 'real')\n",
    "attack_dir = os.path.join(new_dataset_dir, 'attack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1e15cb10-aa4b-43c5-aeac-4a66235a01dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images from real: 100%|██████████████████████████████████████████████████| 19746/19746 [03:39<00:00, 90.08it/s]\n",
      "Loading images from attack: 100%|████████████████████████████████████████████████| 57925/57925 [11:40<00:00, 82.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create numpy arrays for MSU dataset\n",
    "X_msu, y_msu, S_msu = create_numpy_arrays(real_dir, attack_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6d4f122a-408e-464c-a0f8-d65b07df4e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_msu: (77671, 224, 224, 3)\n",
      "Shape of y_msu: (77671,)\n",
      "Shape of S_msu: (77671,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_msu:\", X_msu.shape)\n",
    "print(\"Shape of y_msu:\", y_msu.shape)\n",
    "print(\"Shape of S_msu:\", S_msu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5bade6d9-d4b5-456c-a9f2-29183e294b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy arrays saved successfully.\n"
     ]
    }
   ],
   "source": [
    "np.save('X_msu.npy', X_msu)\n",
    "np.save('y_msu.npy', y_msu)\n",
    "np.save('S_msu.npy', S_msu)\n",
    "\n",
    "print(\"Numpy arrays saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e651c4-10ea-4071-8a9a-02d21f987bae",
   "metadata": {},
   "source": [
    "## Create numpy arrays for the combined dataset (MUAA + MSU-MFSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5a3436d1-4ae1-4a3f-a695-77c7ce0b5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the indices of real and attack images\n",
    "real_indices = np.where(S_msu == 0)[0]\n",
    "attack_indices = np.where(S_msu == 1)[0]\n",
    "\n",
    "# Randomly select 19,000 real and 19,000 attack images\n",
    "np.random.seed(42)  # Set the seed for reproducibility\n",
    "selected_real_indices = np.random.choice(real_indices, 19000, replace=False)\n",
    "selected_attack_indices = np.random.choice(attack_indices, 19000, replace=False)\n",
    "\n",
    "# Combine the selected indices\n",
    "selected_indices = np.concatenate((selected_real_indices, selected_attack_indices))\n",
    "\n",
    "# Shuffle the indices to mix real and attack images\n",
    "np.random.shuffle(selected_indices)\n",
    "\n",
    "# Select the corresponding images and labels from the MSU dataset\n",
    "X_msu = X_msu[selected_indices]\n",
    "y_msu = y_msu[selected_indices]\n",
    "S_msu = S_msu[selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "62787e2b-96b9-4f6e-aa74-49162f031528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_msu: (38000, 224, 224, 3)\n",
      "Shape of y_msu: (38000,)\n",
      "Shape of S_msu: (38000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_msu:\", X_msu.shape)\n",
    "print(\"Shape of y_msu:\", y_msu.shape)\n",
    "print(\"Shape of S_msu:\", S_msu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e7591930-262c-4789-93cc-dc86e55826ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_combined: (50547, 224, 224, 3)\n",
      "Shape of y_combined: (50547,)\n",
      "Shape of S_combined: (50547,)\n"
     ]
    }
   ],
   "source": [
    "# Combine NUAA and MSU datasets\n",
    "\n",
    "X_combined = np.concatenate((X_nuaa, X_msu), axis=0)\n",
    "print(\"Shape of X_combined:\", X_combined.shape)\n",
    "\n",
    "y_combined = np.concatenate((y_nuaa, y_msu), axis=0)\n",
    "print(\"Shape of y_combined:\", y_combined.shape)\n",
    "\n",
    "S_combined = np.concatenate((S_nuaa, S_msu), axis=0)\n",
    "print(\"Shape of S_combined:\", S_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5ae1a805-6a4c-418e-81b5-6ecbe1c8dfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 50544 50545 50546]\n",
      "[31740 26556 31153 ... 34568 33012 41576]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the combined dataset\n",
    "indices = np.arange(X_combined.shape[0])\n",
    "print(indices)\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fa0a9f8c-58d3-4d69-b15f-139f4f073c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the shuffled order to the combined dataset\n",
    "X_combined_shuffled = X_combined[indices]\n",
    "y_combined_shuffled = y_combined[indices]\n",
    "S_combined_shuffled = S_combined[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fc04717c-f972-473a-949d-5e911513d16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50547, 224, 224, 3)\n",
      "(50547,)\n",
      "(50547,)\n"
     ]
    }
   ],
   "source": [
    "print(X_combined_shuffled.shape)\n",
    "print(y_combined_shuffled.shape)\n",
    "print(S_combined_shuffled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3f6ee8c6-a62a-4cbc-84a2-1fccbec33206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy arrays saved successfully.\n"
     ]
    }
   ],
   "source": [
    "np.save('X_combined.npy', X_combined_shuffled)\n",
    "np.save('y_combined.npy', y_combined_shuffled)\n",
    "np.save('S_combined.npy', S_combined_shuffled)\n",
    "\n",
    "print(\"Numpy arrays saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
